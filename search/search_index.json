{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Raspbernetes \u00b6 Work in progress This document is a work in progress. This repo is a declarative implementation of a Kubernetes cluster. It's using the GitOps Toolkit known as Fluxv2. Mission \u00b6 The goal is to demonstrates how to implement enterprise-grade security, observability, and overall cluster config management using GitOps in a Kubernetes cluster. Story \u00b6 This project ...","title":"Introduction"},{"location":"#raspbernetes","text":"Work in progress This document is a work in progress. This repo is a declarative implementation of a Kubernetes cluster. It's using the GitOps Toolkit known as Fluxv2.","title":"Raspbernetes"},{"location":"#mission","text":"The goal is to demonstrates how to implement enterprise-grade security, observability, and overall cluster config management using GitOps in a Kubernetes cluster.","title":"Mission"},{"location":"#story","text":"This project ...","title":"Story"},{"location":"contributing/","text":"Contributing \u00b6 Work in progress This document is a work in progress. Contributors \u00b6 This project exists thanks to all the people who contribute.","title":"Contributing"},{"location":"contributing/#contributing","text":"Work in progress This document is a work in progress.","title":"Contributing"},{"location":"contributing/#contributors","text":"This project exists thanks to all the people who contribute.","title":"Contributors"},{"location":"designs/secret-management/","text":"Secret Management \u00b6 Work in progress This document is a work in progress. Requirements \u00b6 Store encrypted secrets in Git DIFF ciphertext in Git View secret metadata without decryption View secret spec structure without decryption Decrypt secrets from any machine Support multi-cluster encrypt/decrypt keys Support kube RBAC for CRUD operations Support IAM for decryption Secrets decoupled from application configuration Protection against committing unencrypted secrets to Git Proposed Solution \u00b6 A combination of Sealed Secrets with SOPs... But why? Justification: SOPs decryption in conjunction with Flux decrypts secrets on the fly and applies them as encoded Kubernetes secret resources, which reduces the ability to issue permissive RBAC controls to engineers without exposing the secret. Whereas Sealed Secrets would provide the ability to grant permissive RBAC controls to the encrypted custom resource that it provides whilst still protecting the sensitive information. Sealed Secrets can only be decrypted by the operator itself in the cluster or by utilizing the private key. If a cluster becomes unavailable and no longer recoverable you will need to recover these secrets, hence persisting the private key is required, however this key must also be protected and encrypted. SOPs natively integrates with cloud KMS and can encrypt the Sealed Secrets private key. Utilizing both Sealed Secerets and SOPs meets the following criteria: Store encrypted secrets in Git Sealed Secrets allows for secrets to be stored as encrypted values in source control securely. SOPs likewise allows for the private key to be stored as an encrypted value in source control. DIFF ciphertext in Git Both Sealed Secrets and SOPs provide the ciphertext in source control which can be versioned and DIFF'ed between changes. View secret metadata without decryption Sealed Secrets doesn't encrypted the secret metadata which is useful to view the name and namespace attributes of a secret resource. SOPs by default will encrypt these values. View secret spec structure without decryption Both Sealed Secrets and SOPs provide the ability to view the data keys in the secret resource whilst encryption of the values to those keys. Decrypt secrets from any machine SOPs integrates with cloud KMS therefore no manual GPG key management is required. Support multi-cluster encrypt/decrypt keys Both Sealed Secrets and SOPs provide the capability to manage multi-cluster encrypt/decrypt keys, however, Sealed Secrets public cert ensures ease of use in the OSS environment without additional IAM. Support kube RBAC for CRUD operations Sealed Secrets provides a better RBAC model as it allows provisioning CRUD operations to the custom resource, and strict RBAC protection of the secret resource, whilst also allowing permissive RBAC of the encrypted secret custom resource. Support IAM for decryption SOPs provides integration with cloud KMS which inherently grants strict IAM models. Access to the private key for offline decryption should be extremely protected and only used in a break-glass scenario. Secrets decoupled from application configuration Applications should consume native Kubernetes secrets resources and be decoupled from the implementation of the secret provisioning. Both Sealed Secrets and SOPs can provide his behaviour. Protection against committing unencrypted secrets to Git Currently a missing fundamental component is missing in both these tools which prohibits committing unencrypted values to source control. This is a function that will need to be addressed via additional tooling and/or automation.","title":"Secret Management"},{"location":"designs/secret-management/#secret-management","text":"Work in progress This document is a work in progress.","title":"Secret Management"},{"location":"designs/secret-management/#requirements","text":"Store encrypted secrets in Git DIFF ciphertext in Git View secret metadata without decryption View secret spec structure without decryption Decrypt secrets from any machine Support multi-cluster encrypt/decrypt keys Support kube RBAC for CRUD operations Support IAM for decryption Secrets decoupled from application configuration Protection against committing unencrypted secrets to Git","title":"Requirements"},{"location":"designs/secret-management/#proposed-solution","text":"A combination of Sealed Secrets with SOPs... But why? Justification: SOPs decryption in conjunction with Flux decrypts secrets on the fly and applies them as encoded Kubernetes secret resources, which reduces the ability to issue permissive RBAC controls to engineers without exposing the secret. Whereas Sealed Secrets would provide the ability to grant permissive RBAC controls to the encrypted custom resource that it provides whilst still protecting the sensitive information. Sealed Secrets can only be decrypted by the operator itself in the cluster or by utilizing the private key. If a cluster becomes unavailable and no longer recoverable you will need to recover these secrets, hence persisting the private key is required, however this key must also be protected and encrypted. SOPs natively integrates with cloud KMS and can encrypt the Sealed Secrets private key. Utilizing both Sealed Secerets and SOPs meets the following criteria: Store encrypted secrets in Git Sealed Secrets allows for secrets to be stored as encrypted values in source control securely. SOPs likewise allows for the private key to be stored as an encrypted value in source control. DIFF ciphertext in Git Both Sealed Secrets and SOPs provide the ciphertext in source control which can be versioned and DIFF'ed between changes. View secret metadata without decryption Sealed Secrets doesn't encrypted the secret metadata which is useful to view the name and namespace attributes of a secret resource. SOPs by default will encrypt these values. View secret spec structure without decryption Both Sealed Secrets and SOPs provide the ability to view the data keys in the secret resource whilst encryption of the values to those keys. Decrypt secrets from any machine SOPs integrates with cloud KMS therefore no manual GPG key management is required. Support multi-cluster encrypt/decrypt keys Both Sealed Secrets and SOPs provide the capability to manage multi-cluster encrypt/decrypt keys, however, Sealed Secrets public cert ensures ease of use in the OSS environment without additional IAM. Support kube RBAC for CRUD operations Sealed Secrets provides a better RBAC model as it allows provisioning CRUD operations to the custom resource, and strict RBAC protection of the secret resource, whilst also allowing permissive RBAC of the encrypted secret custom resource. Support IAM for decryption SOPs provides integration with cloud KMS which inherently grants strict IAM models. Access to the private key for offline decryption should be extremely protected and only used in a break-glass scenario. Secrets decoupled from application configuration Applications should consume native Kubernetes secrets resources and be decoupled from the implementation of the secret provisioning. Both Sealed Secrets and SOPs can provide his behaviour. Protection against committing unencrypted secrets to Git Currently a missing fundamental component is missing in both these tools which prohibits committing unencrypted values to source control. This is a function that will need to be addressed via additional tooling and/or automation.","title":"Proposed Solution"},{"location":"faq/","text":"Frequently Asked Questions \u00b6 Work in progress This document is a work in progress.","title":"FAQ"},{"location":"faq/#frequently-asked-questions","text":"Work in progress This document is a work in progress.","title":"Frequently Asked Questions"},{"location":"get-started/","text":"Getting Started \u00b6 Work in progress This document is a work in progress. Install the CLI tool \u00b6 For all installation methods visit the Flux install guide brew install fluxcd/tap/flux Install Flux \u00b6 For the full installation guide visit the Flux bootstrap guide Validate the cluster and its connectivity kubectl cluster-info Export your GitHub personal access token, username, repository and cluster export GITHUB_TOKEN = <your-token> export GITHUB_USER = <your-username> export GITHUB_REPO = <your-repo> export CLUSTER = <target-cluster> Verify that your cluster satisfies the prerequisites flux check --pre Run the bootstrap command to install Flux flux bootstrap github \\ --owner = \" ${ GITHUB_USER } \" \\ --repository = \" ${ GITHUB_REPO } \" \\ --path = k8s/clusters/ \" ${ CLUSTER } \" \\ --branch = main \\ --personal Note: If you have network issues with Flux starting you may need to set --network-policies=false in the bootstrap command. You may also use the automated installation script - Either override the defaults in the install script or as environment variables.","title":"Get Started"},{"location":"get-started/#getting-started","text":"Work in progress This document is a work in progress.","title":"Getting Started"},{"location":"get-started/#install-the-cli-tool","text":"For all installation methods visit the Flux install guide brew install fluxcd/tap/flux","title":"Install the CLI tool"},{"location":"get-started/#install-flux","text":"For the full installation guide visit the Flux bootstrap guide Validate the cluster and its connectivity kubectl cluster-info Export your GitHub personal access token, username, repository and cluster export GITHUB_TOKEN = <your-token> export GITHUB_USER = <your-username> export GITHUB_REPO = <your-repo> export CLUSTER = <target-cluster> Verify that your cluster satisfies the prerequisites flux check --pre Run the bootstrap command to install Flux flux bootstrap github \\ --owner = \" ${ GITHUB_USER } \" \\ --repository = \" ${ GITHUB_REPO } \" \\ --path = k8s/clusters/ \" ${ CLUSTER } \" \\ --branch = main \\ --personal Note: If you have network issues with Flux starting you may need to set --network-policies=false in the bootstrap command. You may also use the automated installation script - Either override the defaults in the install script or as environment variables.","title":"Install Flux"},{"location":"guides/installation/","text":"Installation \u00b6 Work in progress This document is a work in progress.","title":"Installation"},{"location":"guides/installation/#installation","text":"Work in progress This document is a work in progress.","title":"Installation"},{"location":"guides/mozilla-sops/","text":"SOPs \u00b6 Work in progress This document is a work in progress.","title":"Mozilla SOPS"},{"location":"guides/mozilla-sops/#sops","text":"Work in progress This document is a work in progress.","title":"SOPs"},{"location":"guides/repo-structure/","text":"Flux Repository Structure \u00b6 TL;DR Quick Start \u00b6 If you're familiar with Kustomize and how it operates within the Flux ecosystem this will provide a quick overview: . \u2514\u2500\u2500 k8s/ \u251c\u2500\u2500 clusters/ \u2502 \u251c\u2500\u2500 production/ # One folder per cluster. \u2502 \u2502 \u251c\u2500\u2500 flux-system/ # Folder containing flux-system manifests. \u2502 \u2502 \u2502 \u251c\u2500\u2500 ... # Flux component resource manifests. \u2502 \u2502 \u2502 \u2514\u2500\u2500 kustomization.yaml # Generated kustomization per cluster bootstrap. \u2502 \u2502 \u2514\u2500\u2500 kustomization.yaml # Kustomization per cluster referring all manifests in core and namespace directory. \u2502 \u2514\u2500\u2500 staging/ \u2502 \u251c\u2500\u2500 flux-system/ \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u2514\u2500\u2500 kustomization.yaml \u2502 \u2514\u2500\u2500 kustomization.yaml \u251c\u2500\u2500 core/ \u2502 \u251c\u2500\u2500 base/ \u2502 \u2502 \u2514\u2500\u2500 .../ # One folder per resource type and/or app with its core dependency with prune disabled. \u2502 \u2502 \u2514\u2500\u2500 application/ # One folder per application with core manifests. \u2502 \u2502 \u2514\u2500\u2500 kustomization.yaml # Kustomization per core application. \u2502 \u2514\u2500\u2500 overlays/ \u2502 \u251c\u2500\u2500 production/ \u2502 \u2502 \u251c\u2500\u2500 kustomization.yaml # Kustomization per cluster referencing each core app required. \u2502 \u2502 \u2514\u2500\u2500 patch.yaml # Optional patch for each environment. \u2502 \u2514\u2500\u2500 staging/ \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2514\u2500\u2500 patch.yaml \u2514\u2500\u2500 namespaces/ \u251c\u2500\u2500 base/ \u2502 \u2514\u2500\u2500 namespace/ # One folder per namespace containing base resources. \u2502 \u251c\u2500\u2500 namespace.yaml # Namespace manifest. \u2502 \u251c\u2500\u2500 kustomization.yaml # Kustomization per namespace referring all manifests in this current directory. \u2502 \u2514\u2500\u2500 application/ # Folder per app containing manifests and patches for each application. \u2502 \u2514\u2500\u2500 kustomizaiton.yaml # Kustomization per app referring all manifests in this directory. \u2514\u2500\u2500 overlays/ \u251c\u2500\u2500 production/ \u2502 \u251c\u2500\u2500 kustomization.yaml # Kustomization per cluster referencing each namespace and app required. \u2502 \u2514\u2500\u2500 patch.yaml # Optional patch for each environment. \u2514\u2500\u2500 staging/ \u251c\u2500\u2500 kustomization.yaml \u2514\u2500\u2500 patch.yaml Repository Structure Breakdown \u00b6 This Git repository contains the following directories: clusters dir contains the Flux configuration per cluster. core dir contains cluster resources that are core prerequisites to the cluster. namespaces dir contains namespaces and application workloads per cluster. . \u251c\u2500\u2500 clusters/ \u2502 \u251c\u2500\u2500 production \u2502 \u2514\u2500\u2500 staging \u251c\u2500\u2500 core/ \u2502 \u251c\u2500\u2500 base \u2502 \u2514\u2500\u2500 overlays/ \u2502 \u251c\u2500\u2500 production \u2502 \u2514\u2500\u2500 staging \u2514\u2500\u2500 namespaces/ \u251c\u2500\u2500 base \u2514\u2500\u2500 overlays/ \u251c\u2500\u2500 production \u2514\u2500\u2500 staging The clusters/ dir contains configuration for each cluster definition and the infrastructure as code for each relevant cluster where applicable. The core/ dir contains all resources that are prerequisites to namespaces and workloads, this includes resources: CRDs, certain applications like Istio and Gatekeeper that must exist prior to other workloads, and crossplane resources that provisions infrastructure. The namespaces/ configuration is structured into: namespaces/base/ dir contains namespaces and application workload resources. namespaces/overlays/production/ dir contains the production cluster values and references what base components to deploy. namespaces/overlays/staging/ dir contains the stating cluster values and references what base components to deploy. . \u2514\u2500\u2500 namespaces/ \u251c\u2500\u2500 base/ \u2502 \u2514\u2500\u2500 namespace/ \u2502 \u251c\u2500\u2500 namespace.yaml \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2514\u2500\u2500 application/ \u2502 \u251c\u2500\u2500 helmrelease.yaml \u2502 \u2514\u2500\u2500 kustomizaiton.yaml \u2514\u2500\u2500 overlays/ \u251c\u2500\u2500 production/ \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2514\u2500\u2500 patch.yaml \u2514\u2500\u2500 staging/ \u2514\u2500\u2500 ... In namespaces/base/ dir will be a hierarchy of all namespace/ dirs which will contain application resources. Each cluster overlay includes each namespace and/or application which is explicitly referenced; The base application configuration is defined with the following values: apiVersion: helm.toolkit.fluxcd.io/v2beta1 kind: HelmRelease metadata: name: metallb namespace: network-system spec: interval: 5m chart: spec: chart: metallb version: 2 .0.4 sourceRef: kind: HelmRepository name: bitnami-charts namespace: flux-system interval: 10m values: configInline: address-pools: - name: default protocol: layer2 addresses: - 192 .168.1.150-192.168.1.155 In namespaces/overlays/production/ dir we have a Kustomize patch file(s) with the production cluster specific values: apiVersion: helm.toolkit.fluxcd.io/v2beta1 kind: HelmRelease metadata: name: metallb namespace: network-system spec: values: configInline: address-pools: - name: default protocol: layer2 addresses: - 192 .168.1.150-192.168.1.155 Note that whilst using Kustomize we can overwrite default values; in this example the default MetalLB address pool will be patched in the production cluster to a unique pool.","title":"Repository Structure"},{"location":"guides/repo-structure/#flux-repository-structure","text":"","title":"Flux Repository Structure"},{"location":"guides/repo-structure/#tldr-quick-start","text":"If you're familiar with Kustomize and how it operates within the Flux ecosystem this will provide a quick overview: . \u2514\u2500\u2500 k8s/ \u251c\u2500\u2500 clusters/ \u2502 \u251c\u2500\u2500 production/ # One folder per cluster. \u2502 \u2502 \u251c\u2500\u2500 flux-system/ # Folder containing flux-system manifests. \u2502 \u2502 \u2502 \u251c\u2500\u2500 ... # Flux component resource manifests. \u2502 \u2502 \u2502 \u2514\u2500\u2500 kustomization.yaml # Generated kustomization per cluster bootstrap. \u2502 \u2502 \u2514\u2500\u2500 kustomization.yaml # Kustomization per cluster referring all manifests in core and namespace directory. \u2502 \u2514\u2500\u2500 staging/ \u2502 \u251c\u2500\u2500 flux-system/ \u2502 \u2502 \u251c\u2500\u2500 ... \u2502 \u2502 \u2514\u2500\u2500 kustomization.yaml \u2502 \u2514\u2500\u2500 kustomization.yaml \u251c\u2500\u2500 core/ \u2502 \u251c\u2500\u2500 base/ \u2502 \u2502 \u2514\u2500\u2500 .../ # One folder per resource type and/or app with its core dependency with prune disabled. \u2502 \u2502 \u2514\u2500\u2500 application/ # One folder per application with core manifests. \u2502 \u2502 \u2514\u2500\u2500 kustomization.yaml # Kustomization per core application. \u2502 \u2514\u2500\u2500 overlays/ \u2502 \u251c\u2500\u2500 production/ \u2502 \u2502 \u251c\u2500\u2500 kustomization.yaml # Kustomization per cluster referencing each core app required. \u2502 \u2502 \u2514\u2500\u2500 patch.yaml # Optional patch for each environment. \u2502 \u2514\u2500\u2500 staging/ \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2514\u2500\u2500 patch.yaml \u2514\u2500\u2500 namespaces/ \u251c\u2500\u2500 base/ \u2502 \u2514\u2500\u2500 namespace/ # One folder per namespace containing base resources. \u2502 \u251c\u2500\u2500 namespace.yaml # Namespace manifest. \u2502 \u251c\u2500\u2500 kustomization.yaml # Kustomization per namespace referring all manifests in this current directory. \u2502 \u2514\u2500\u2500 application/ # Folder per app containing manifests and patches for each application. \u2502 \u2514\u2500\u2500 kustomizaiton.yaml # Kustomization per app referring all manifests in this directory. \u2514\u2500\u2500 overlays/ \u251c\u2500\u2500 production/ \u2502 \u251c\u2500\u2500 kustomization.yaml # Kustomization per cluster referencing each namespace and app required. \u2502 \u2514\u2500\u2500 patch.yaml # Optional patch for each environment. \u2514\u2500\u2500 staging/ \u251c\u2500\u2500 kustomization.yaml \u2514\u2500\u2500 patch.yaml","title":"TL;DR Quick Start"},{"location":"guides/repo-structure/#repository-structure-breakdown","text":"This Git repository contains the following directories: clusters dir contains the Flux configuration per cluster. core dir contains cluster resources that are core prerequisites to the cluster. namespaces dir contains namespaces and application workloads per cluster. . \u251c\u2500\u2500 clusters/ \u2502 \u251c\u2500\u2500 production \u2502 \u2514\u2500\u2500 staging \u251c\u2500\u2500 core/ \u2502 \u251c\u2500\u2500 base \u2502 \u2514\u2500\u2500 overlays/ \u2502 \u251c\u2500\u2500 production \u2502 \u2514\u2500\u2500 staging \u2514\u2500\u2500 namespaces/ \u251c\u2500\u2500 base \u2514\u2500\u2500 overlays/ \u251c\u2500\u2500 production \u2514\u2500\u2500 staging The clusters/ dir contains configuration for each cluster definition and the infrastructure as code for each relevant cluster where applicable. The core/ dir contains all resources that are prerequisites to namespaces and workloads, this includes resources: CRDs, certain applications like Istio and Gatekeeper that must exist prior to other workloads, and crossplane resources that provisions infrastructure. The namespaces/ configuration is structured into: namespaces/base/ dir contains namespaces and application workload resources. namespaces/overlays/production/ dir contains the production cluster values and references what base components to deploy. namespaces/overlays/staging/ dir contains the stating cluster values and references what base components to deploy. . \u2514\u2500\u2500 namespaces/ \u251c\u2500\u2500 base/ \u2502 \u2514\u2500\u2500 namespace/ \u2502 \u251c\u2500\u2500 namespace.yaml \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2514\u2500\u2500 application/ \u2502 \u251c\u2500\u2500 helmrelease.yaml \u2502 \u2514\u2500\u2500 kustomizaiton.yaml \u2514\u2500\u2500 overlays/ \u251c\u2500\u2500 production/ \u2502 \u251c\u2500\u2500 kustomization.yaml \u2502 \u2514\u2500\u2500 patch.yaml \u2514\u2500\u2500 staging/ \u2514\u2500\u2500 ... In namespaces/base/ dir will be a hierarchy of all namespace/ dirs which will contain application resources. Each cluster overlay includes each namespace and/or application which is explicitly referenced; The base application configuration is defined with the following values: apiVersion: helm.toolkit.fluxcd.io/v2beta1 kind: HelmRelease metadata: name: metallb namespace: network-system spec: interval: 5m chart: spec: chart: metallb version: 2 .0.4 sourceRef: kind: HelmRepository name: bitnami-charts namespace: flux-system interval: 10m values: configInline: address-pools: - name: default protocol: layer2 addresses: - 192 .168.1.150-192.168.1.155 In namespaces/overlays/production/ dir we have a Kustomize patch file(s) with the production cluster specific values: apiVersion: helm.toolkit.fluxcd.io/v2beta1 kind: HelmRelease metadata: name: metallb namespace: network-system spec: values: configInline: address-pools: - name: default protocol: layer2 addresses: - 192 .168.1.150-192.168.1.155 Note that whilst using Kustomize we can overwrite default values; in this example the default MetalLB address pool will be patched in the production cluster to a unique pool.","title":"Repository Structure Breakdown"},{"location":"guides/sealed-secrets/","text":"Sealed Secrets \u00b6 Work in progress This document is a work in progress. When bootstrapping your cluster for the first time you must store a unique public & private key for your sealed-secrets controller to use for managing your sensitive keys and passwords in your Kubernetes cluster. Install the CLI tool \u00b6 For all installation methods visit the Sealed Secrets install guide brew install kubeseal Remove Existing Key & Cert \u00b6 Remove the sealed-secrets master key currently present in this repository rm -f k8s/clusters/<cluster>/secrets/sealed-secret-private-key.enc.yaml Remove the sealed-secrets public cert currently present in this repository rm -f k8s/clusters/<cluster>/secrets/sealed-secret-public-cert.yaml Store New Key & Cert \u00b6 Private Key \u00b6 Once sealed-secrets has been re-deployed to a running cluster you must store the private key and public cert in this repository. Get the generated sealed-secret private key kubectl get secret -n kube-system -l sealedsecrets.bitnami.com/sealed-secrets-key -o yaml > k8s/clusters/<cluster>/secrets/sealed-secret-private-key.yaml Encrypt the sealed-secret private key using SOPs sops --encrypt k8s/clusters/<cluster>/secrets/sealed-secret-private-key.yaml > k8s/clusters/<cluster>/secrets/sealed-secret-private-key.enc.yaml Remove unencrypted private key rm -f k8s/clusters/<cluster>/secrets/sealed-secret-private-key.yaml Public Cert \u00b6 Fetch the generated sealed-secret public cert and store it kubeseal \\ --controller-name sealed-secrets \\ --fetch-cert > k8s/clusters/<cluster>/secrets/sealed-secret-public-cert.yaml Encrypt Secrets \u00b6 With a newly generated private key from sealed-secrets you will need to re-encrypt all of the existing required secrets. Create an alias for the CLI tool ( recommended ) alias kubeseal = 'kubeseal --cert k8s/clusters/<cluster>/secrets/sealed-secret-public-cert.pem --controller-name sealed-secrets --format yaml' Encrypt new Kubernetes secret kubeseal < secret.yaml > secret.encrypted.yaml Remove the unencrypted secret You must encrypt your secrets with the correct cluster public certificate. For more in-depth instructions the official docs can be found here Offline Decryption \u00b6 Storing the private key allows an offline decryption, this is not recommended and should only be used in a break-glass scenario when the cluster is down and secrets must be accessed. Unencrypt the sealed-secret private key sops --decrypt k8s/clusters/<cluster>/secrets/sealed-secret-private-key.enc.yaml -oyaml > k8s/clusters/<cluster>/secrets/sealed-secret-private-key.yaml Unseal the encrypted secret(s) kubeseal --recovery-unseal --recovery-private-key ./k8s/clusters/<cluster>/secrets/sealed-secret-private-key.yaml < <path-to-file>/secret.encrypted.yaml Re-Encrypt the sealed-secret private key sops --encrypt k8s/clusters/<cluster>/secrets/sealed-secret-private-key.yaml > k8s/clusters/<cluster>/secrets/sealed-secret-private-key.enc.yaml Remove the unencrypted private key rm -f k8s/clusters/<cluster>/secrets/sealed-secret-private-key.yaml","title":"Sealed Secrets"},{"location":"guides/sealed-secrets/#sealed-secrets","text":"Work in progress This document is a work in progress. When bootstrapping your cluster for the first time you must store a unique public & private key for your sealed-secrets controller to use for managing your sensitive keys and passwords in your Kubernetes cluster.","title":"Sealed Secrets"},{"location":"guides/sealed-secrets/#install-the-cli-tool","text":"For all installation methods visit the Sealed Secrets install guide brew install kubeseal","title":"Install the CLI tool"},{"location":"guides/sealed-secrets/#remove-existing-key-cert","text":"Remove the sealed-secrets master key currently present in this repository rm -f k8s/clusters/<cluster>/secrets/sealed-secret-private-key.enc.yaml Remove the sealed-secrets public cert currently present in this repository rm -f k8s/clusters/<cluster>/secrets/sealed-secret-public-cert.yaml","title":"Remove Existing Key &amp; Cert"},{"location":"guides/sealed-secrets/#store-new-key-cert","text":"","title":"Store New Key &amp; Cert"},{"location":"guides/sealed-secrets/#private-key","text":"Once sealed-secrets has been re-deployed to a running cluster you must store the private key and public cert in this repository. Get the generated sealed-secret private key kubectl get secret -n kube-system -l sealedsecrets.bitnami.com/sealed-secrets-key -o yaml > k8s/clusters/<cluster>/secrets/sealed-secret-private-key.yaml Encrypt the sealed-secret private key using SOPs sops --encrypt k8s/clusters/<cluster>/secrets/sealed-secret-private-key.yaml > k8s/clusters/<cluster>/secrets/sealed-secret-private-key.enc.yaml Remove unencrypted private key rm -f k8s/clusters/<cluster>/secrets/sealed-secret-private-key.yaml","title":"Private Key"},{"location":"guides/sealed-secrets/#public-cert","text":"Fetch the generated sealed-secret public cert and store it kubeseal \\ --controller-name sealed-secrets \\ --fetch-cert > k8s/clusters/<cluster>/secrets/sealed-secret-public-cert.yaml","title":"Public Cert"},{"location":"guides/sealed-secrets/#encrypt-secrets","text":"With a newly generated private key from sealed-secrets you will need to re-encrypt all of the existing required secrets. Create an alias for the CLI tool ( recommended ) alias kubeseal = 'kubeseal --cert k8s/clusters/<cluster>/secrets/sealed-secret-public-cert.pem --controller-name sealed-secrets --format yaml' Encrypt new Kubernetes secret kubeseal < secret.yaml > secret.encrypted.yaml Remove the unencrypted secret You must encrypt your secrets with the correct cluster public certificate. For more in-depth instructions the official docs can be found here","title":"Encrypt Secrets"},{"location":"guides/sealed-secrets/#offline-decryption","text":"Storing the private key allows an offline decryption, this is not recommended and should only be used in a break-glass scenario when the cluster is down and secrets must be accessed. Unencrypt the sealed-secret private key sops --decrypt k8s/clusters/<cluster>/secrets/sealed-secret-private-key.enc.yaml -oyaml > k8s/clusters/<cluster>/secrets/sealed-secret-private-key.yaml Unseal the encrypted secret(s) kubeseal --recovery-unseal --recovery-private-key ./k8s/clusters/<cluster>/secrets/sealed-secret-private-key.yaml < <path-to-file>/secret.encrypted.yaml Re-Encrypt the sealed-secret private key sops --encrypt k8s/clusters/<cluster>/secrets/sealed-secret-private-key.yaml > k8s/clusters/<cluster>/secrets/sealed-secret-private-key.enc.yaml Remove the unencrypted private key rm -f k8s/clusters/<cluster>/secrets/sealed-secret-private-key.yaml","title":"Offline Decryption"},{"location":"hardware/pre-rockpi4c/","text":"Rock Pi 4C \u00b6 The following are prerequisites to create a Kubernetes on the RockPi(s) 4C Hardware \u00b6 Since I decided to use an eMMC module rather than the typical microSD I needed to purchase either a eMMC to USB adapter or eMMC to microSD adapter. I purchased both and they work equally as fine except you can save some $$$ if you choose to purchase the eMMC to microSD adapter. Either can be purchased with the below links: eMMC microSD adapter eMMC USB3.0 adapter Instruction \u00b6 When running apt-get upgrade you will get the following error: Err:4 http://apt.radxa.com/buster-stable buster InRelease The following signatures were invalid: EXPKEYSIG 5761288B2B52CC90 Radxa <dev@radxa.com> Reading package lists... Done W: GPG error: http://apt.radxa.com/buster-stable buster InRelease: The following signatures were invalid: EXPKEYSIG 5761288B2B52CC90 Radxa <dev@radxa.com> E: The repository 'http://apt.radxa.com/buster-stable buster InRelease' is not signed. N: Updating from such a repository can ' t be done securely, and is therefore disabled by default. N: See apt-secure ( 8 ) manpage for repository creation and user configuration details. To fix this error use the following steps. Install wget sudo apt-get update sudo apt-get install -y wget Edit /etc/apt/sources.list.d/apt-radxa-com.list deb http://apt.radxa.com/buster-stable/ buster main deb http://apt.radxa.com/buster-testing/ buster main Add the public apt-key wget -O - apt.radxa.com/buster-testing/public.key | sudo apt-key add - wget -O - apt.radxa.com/buster-stable/public.key | sudo apt-key add - You will no longer have the above mentioned issue. Follow instructions here to complete the Kubernetes bootstrap process: https://github.com/raspbernetes/k8s-cluster-installation","title":"RockPis"},{"location":"hardware/pre-rockpi4c/#rock-pi-4c","text":"The following are prerequisites to create a Kubernetes on the RockPi(s) 4C","title":"Rock Pi 4C"},{"location":"hardware/pre-rockpi4c/#hardware","text":"Since I decided to use an eMMC module rather than the typical microSD I needed to purchase either a eMMC to USB adapter or eMMC to microSD adapter. I purchased both and they work equally as fine except you can save some $$$ if you choose to purchase the eMMC to microSD adapter. Either can be purchased with the below links: eMMC microSD adapter eMMC USB3.0 adapter","title":"Hardware"},{"location":"hardware/pre-rockpi4c/#instruction","text":"When running apt-get upgrade you will get the following error: Err:4 http://apt.radxa.com/buster-stable buster InRelease The following signatures were invalid: EXPKEYSIG 5761288B2B52CC90 Radxa <dev@radxa.com> Reading package lists... Done W: GPG error: http://apt.radxa.com/buster-stable buster InRelease: The following signatures were invalid: EXPKEYSIG 5761288B2B52CC90 Radxa <dev@radxa.com> E: The repository 'http://apt.radxa.com/buster-stable buster InRelease' is not signed. N: Updating from such a repository can ' t be done securely, and is therefore disabled by default. N: See apt-secure ( 8 ) manpage for repository creation and user configuration details. To fix this error use the following steps. Install wget sudo apt-get update sudo apt-get install -y wget Edit /etc/apt/sources.list.d/apt-radxa-com.list deb http://apt.radxa.com/buster-stable/ buster main deb http://apt.radxa.com/buster-testing/ buster main Add the public apt-key wget -O - apt.radxa.com/buster-testing/public.key | sudo apt-key add - wget -O - apt.radxa.com/buster-stable/public.key | sudo apt-key add - You will no longer have the above mentioned issue. Follow instructions here to complete the Kubernetes bootstrap process: https://github.com/raspbernetes/k8s-cluster-installation","title":"Instruction"},{"location":"network/certificates/","text":"Certficiate \u00b6 Work in progress This document is a work in progress.","title":"Certificates"},{"location":"network/certificates/#certficiate","text":"Work in progress This document is a work in progress.","title":"Certficiate"},{"location":"network/ip-allocation/","text":"IP Allocation \u00b6 Work in progress This document is a work in progress. Production - Zone A \u00b6 Application/Node Type IP/CIDR keepalived VIP 192.168.1.200/32 k8s-controlplane-01 Control-Plane Node 192.168.1.121/32 k8s-controlplane-02 Control-Plane Node 192.168.1.122/32 k8s-controlplane-03 Control-Plane Node 192.168.1.123/32 k8s-node-01 Node 192.168.1.131/32 k8s-node-01 Node 192.168.1.132/32 k8s-node-01 Node 192.168.1.133/32 metallb Daemonset 192.168.1.150 <-> 192.168.1.155 istio LoadBalancer 192.168.1.150/32 coredns LoadBalancer 192.168.1.151/32 mosquitto LoadBalancer 192.168.1.152/32 zigbee2mqtt LoadBalancer 192.168.1.153/32 zigbee2mqtt (code-server) LoadBalancer 192.168.1.154/32 Production - Zone B \u00b6 Application Type IP/CIDR keepalived VIP 192.168.1.201/32 k8s-controlplane-01 Control-Plane Node 192.168.1.161/32 k8s-controlplane-02 Control-Plane Node 192.168.1.162/32 k8s-controlplane-03 Control-Plane Node 192.168.1.163/32 k8s-node-01 Node 192.168.1.171/32 k8s-node-01 Node 192.168.1.172/32 k8s-node-01 Node 192.168.1.173/32 metallb Daemonset 192.168.1.180 <-> 192.168.1.185 istio LoadBalancer 192.168.1.180/32 coredns LoadBalancer 192.168.1.181/32 mosquitto LoadBalancer 192.168.1.182/32 zigbee2mqtt LoadBalancer 192.168.1.183/32 External Services \u00b6 Application Type IP/CIDR Zigbee Controller N/A 192.168.1.165/32 Ender 5 Pro 3D Printer N/A x.x.x.x/32","title":"IP Allocation"},{"location":"network/ip-allocation/#ip-allocation","text":"Work in progress This document is a work in progress.","title":"IP Allocation"},{"location":"network/ip-allocation/#production-zone-a","text":"Application/Node Type IP/CIDR keepalived VIP 192.168.1.200/32 k8s-controlplane-01 Control-Plane Node 192.168.1.121/32 k8s-controlplane-02 Control-Plane Node 192.168.1.122/32 k8s-controlplane-03 Control-Plane Node 192.168.1.123/32 k8s-node-01 Node 192.168.1.131/32 k8s-node-01 Node 192.168.1.132/32 k8s-node-01 Node 192.168.1.133/32 metallb Daemonset 192.168.1.150 <-> 192.168.1.155 istio LoadBalancer 192.168.1.150/32 coredns LoadBalancer 192.168.1.151/32 mosquitto LoadBalancer 192.168.1.152/32 zigbee2mqtt LoadBalancer 192.168.1.153/32 zigbee2mqtt (code-server) LoadBalancer 192.168.1.154/32","title":"Production - Zone A"},{"location":"network/ip-allocation/#production-zone-b","text":"Application Type IP/CIDR keepalived VIP 192.168.1.201/32 k8s-controlplane-01 Control-Plane Node 192.168.1.161/32 k8s-controlplane-02 Control-Plane Node 192.168.1.162/32 k8s-controlplane-03 Control-Plane Node 192.168.1.163/32 k8s-node-01 Node 192.168.1.171/32 k8s-node-01 Node 192.168.1.172/32 k8s-node-01 Node 192.168.1.173/32 metallb Daemonset 192.168.1.180 <-> 192.168.1.185 istio LoadBalancer 192.168.1.180/32 coredns LoadBalancer 192.168.1.181/32 mosquitto LoadBalancer 192.168.1.182/32 zigbee2mqtt LoadBalancer 192.168.1.183/32","title":"Production - Zone B"},{"location":"network/ip-allocation/#external-services","text":"Application Type IP/CIDR Zigbee Controller N/A 192.168.1.165/32 Ender 5 Pro 3D Printer N/A x.x.x.x/32","title":"External Services"},{"location":"sponsor/","text":"Sponsor \u00b6 Work in progress This document is a work in progress. If you find value to my open source project(s), you can become a sponsor and also don't forget to star the repo . Backers \u00b6 Thank you to all our backers! \ud83d\ude4f [ Become a backer ] Sponsors \u00b6 Support this project by becoming a sponsor. Your logo will show up here with a link to your website. [ Become a sponsor ]","title":"Sponsor"},{"location":"sponsor/#sponsor","text":"Work in progress This document is a work in progress. If you find value to my open source project(s), you can become a sponsor and also don't forget to star the repo .","title":"Sponsor"},{"location":"sponsor/#backers","text":"Thank you to all our backers! \ud83d\ude4f [ Become a backer ]","title":"Backers"},{"location":"sponsor/#sponsors","text":"Support this project by becoming a sponsor. Your logo will show up here with a link to your website. [ Become a sponsor ]","title":"Sponsors"}]}